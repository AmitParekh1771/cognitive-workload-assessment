{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.decoding import Scaler, Vectorizer, CSP, cross_val_multiscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy import io, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_selection(epochs):\n",
    "    X = epochs.get_data()\n",
    "    y = epochs.events[:, -1]\n",
    "    sfreq = epochs.info[\"sfreq\"]\n",
    "\n",
    "    n_trials, n_channels, n_samples = X.shape\n",
    "    \n",
    "    # Calculate corrcoef of each channel pair for each trials\n",
    "    corrcoefs = np.empty((n_trials, n_channels, n_channels))\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        corrcoefs[trial] = np.corrcoef(X[trial])\n",
    "    \n",
    "    corr_1 = np.mean(corrcoefs[y==1], 0)\n",
    "    corr_2 = np.mean(corrcoefs[y==2], 0)\n",
    "    \n",
    "    t_statistic, p_values = stats.ttest_ind(corrcoefs[y==1], corrcoefs[y==2])\n",
    "    \n",
    "    mi_scores = np.sum(p_values < 0.05, axis=1)\n",
    "    mi_scores_mean = np.mean(mi_scores)\n",
    "\n",
    "    distinct_channels = np.where(mi_scores > mi_scores_mean)[0]\n",
    "    corr_channels = np.logical_and(np.abs(corr_1) >= 0.5, np.abs(corr_2) >= 0.5)\n",
    "\n",
    "    psds, freqs = mne.time_frequency.psd_array_welch(X, sfreq, verbose=False)\n",
    "    \n",
    "    # Function to calculate Fisher score for a channel group\n",
    "    def calculate_fisher_score(channel_group):\n",
    "        left_psds = psds[y==1][:, channel_group]\n",
    "        right_psds = psds[y==2][:, channel_group]\n",
    "\n",
    "        # Compute mean and variance for each class and channel\n",
    "        mean_left = np.mean(left_psds, axis=0)\n",
    "        var_left = np.var(left_psds, axis=0)\n",
    "\n",
    "        mean_right = np.mean(right_psds, axis=0)\n",
    "        var_right = np.var(right_psds, axis=0)\n",
    "\n",
    "        # Calculate Fischer score for each channel\n",
    "        return np.mean((mean_left - mean_right) ** 2 / (var_left + var_right))\n",
    "        \n",
    "    max_fisher_score = 0.0\n",
    "    selected_channels = np.where(epochs.info[\"ch_names\"])[0]\n",
    "    \n",
    "    for ch in distinct_channels:\n",
    "        channel_group = np.where(corr_channels[ch])[0]\n",
    "        \n",
    "        fisher_score = calculate_fisher_score(channel_group)\n",
    "        if fisher_score > max_fisher_score:\n",
    "            max_fisher_score = fisher_score\n",
    "            selected_channels = channel_group\n",
    "\n",
    "    return selected_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(([1], [2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(X):\n",
    "    X_transformed = np.concatenate((\n",
    "        np.mean(X, axis=-1),\n",
    "        np.amax(X, axis=-1),\n",
    "        np.amin(X, axis=-1),\n",
    "        np.std(X, axis=-1),\n",
    "        stats.skew(X, axis=-1),\n",
    "        stats.kurtosis(X, axis=-1)\n",
    "    ), axis=-1)  \n",
    "    \n",
    "    return X_transformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrebate import ReliefF\n",
    "\n",
    "class ReliefF_Selector():\n",
    "    def __init__(self):\n",
    "        self.reliefF = ReliefF(n_neighbors=10)\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.reliefF.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.reliefF.top_features_[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrmr import mrmr_classif\n",
    "\n",
    "class MRMR_Selector():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        data = pd.DataFrame(X, copy=True)\n",
    "        labels = pd.Series(y, copy=True)\n",
    "        self.selected_features = mrmr_classif(X=data, y=labels, K=60, show_progress=False)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import chi2 \n",
    "\n",
    "class Chi2_Selector():\n",
    "    def __init__(self):\n",
    "        self.chi2_selector = SelectKBest(chi2, k=60) \n",
    "        self.scaler = MinMaxScaler()\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.chi2_selector.fit(self.scaler.fit_transform(X), y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.chi2_selector.transform(self.scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "class ANOVA_Selector():\n",
    "    def __init__(self):\n",
    "        self.anova_selector = SelectKBest(f_classif, k=60) \n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.anova_selector.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.anova_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KruskalWallis_Selector():\n",
    "    def __init__(self):\n",
    "        self.p_values = []\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for idx in range(X.shape[1]):\n",
    "            _, p_value = stats.kruskal(X[:,idx], y)\n",
    "            self.p_values.append(p_value)\n",
    "\n",
    "        self.selected_features = np.argsort(self.p_values)[:60]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'A'\n",
    "\n",
    "subjects = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10',\n",
    "            '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "            '21', '22', '23', '24', '25', '26', '27', '28', '29']\n",
    "\n",
    "good_subjects = ['01', '02', '03', '04', '06', '07', '08', '09', '10',\n",
    "            '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "            '21', '22', '23', '24', '25', '26', '27', '28', '29']\n",
    "\n",
    "bad_subjects = ['05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject_01: 81.67 ± 9.72 %\n",
      "Subject_02: 75.00 ± 0.00 %\n",
      "Subject_03: 71.67 ± 8.50 %\n",
      "Subject_04: 60.00 ± 14.34 %\n",
      "Subject_06: 73.33 ± 6.24 %\n",
      "Subject_07: 60.00 ± 18.56 %\n",
      "Subject_08: 70.00 ± 12.47 %\n",
      "Subject_09: 91.67 ± 7.45 %\n",
      "Subject_10: 60.00 ± 9.72 %\n",
      "Subject_11: 66.67 ± 19.72 %\n",
      "Subject_12: 61.67 ± 8.50 %\n",
      "Subject_13: 55.00 ± 4.08 %\n",
      "Subject_14: 50.00 ± 19.00 %\n",
      "Subject_15: 66.67 ± 7.45 %\n",
      "Subject_16: 88.33 ± 8.50 %\n",
      "Subject_17: 76.67 ± 11.06 %\n",
      "Subject_18: 65.00 ± 8.16 %\n",
      "Subject_19: 96.67 ± 4.08 %\n",
      "Subject_20: 58.33 ± 11.79 %\n",
      "Subject_21: 61.67 ± 13.54 %\n",
      "Subject_22: 53.33 ± 13.54 %\n",
      "Subject_23: 68.33 ± 3.33 %\n",
      "Subject_24: 70.00 ± 8.50 %\n",
      "Subject_25: 96.67 ± 4.08 %\n",
      "Subject_26: 75.00 ± 17.48 %\n",
      "Subject_27: 95.00 ± 6.67 %\n",
      "Subject_28: 66.67 ± 9.13 %\n",
      "Subject_29: 66.67 ± 5.27 %\n",
      "Score: 70.77 ± 12.86 %\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for subject in good_subjects:\n",
    "    epochs_eeg = mne.read_epochs(f\"epochs_eeg/Dataset_{dataset}/subject_{subject}_epo.fif\", preload=True, verbose=False)\n",
    "\n",
    "    epochs_eeg.crop(tmin=0, tmax=10).pick(picks=\"eeg\")\n",
    "    \n",
    "    X = epochs_eeg.get_data()\n",
    "    y = epochs_eeg.events[:, -1]\n",
    "\n",
    "    cv = ShuffleSplit(5, test_size=0.2, random_state=42)\n",
    "    cv_split = cv.split(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    selector = ReliefF_Selector()\n",
    "    classifier = LinearDiscriminantAnalysis()\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    # selected_eeg_channels = channel_selection(epochs_eeg)\n",
    "    \n",
    "    X_transformed = feature_extraction(X[:, :])\n",
    "    \n",
    "    X_transformed = scaler.fit_transform(X_transformed)\n",
    "    \n",
    "    selector.fit(X_transformed, y)\n",
    "    X_transformed = selector.transform(X_transformed)\n",
    "\n",
    "    for train_idx, test_idx in cv_split:    \n",
    "        classifier.fit(X_transformed[train_idx], y[train_idx])\n",
    "        y_pred = classifier.predict(X_transformed[test_idx])\n",
    "\n",
    "        score = accuracy_score(y[test_idx], y_pred)   \n",
    "\n",
    "        cv_scores.append(score)\n",
    "    \n",
    "    print(f\"Subject_{subject}: {(np.mean(cv_scores)*100):.2f} ± {(np.std(cv_scores)*100):.2f} %\")\n",
    "\n",
    "    scores.append(np.mean(cv_scores))\n",
    "\n",
    "print(f\"Score: {(np.mean(scores)*100):.2f} ± {(np.std(scores)*100):.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"scores/Dataset_{dataset}/EEG_WCS_ReliefF_10_LDA.npy\", scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive-workload-assessment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
